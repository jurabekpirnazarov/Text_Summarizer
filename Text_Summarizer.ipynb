{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "PeynuXYE5fL8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--UBS0EG4Kro"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "Fake news is misleading or false information that is circulated as news. It is often difficult to distinguish between fake and real news, and it isnâ€™t until the situation gets blown out of proportion that it comes to light. The spreading of fake news becomes especially dangerous during times like elections or pandemic situations. Fake rumours and misinformation that pose harm to human lives are threatening to people and the society.\n",
        "\n",
        "Fake news needs to be detected and prevented early, before it causes panic and spreads to a large number of people.\n",
        "\n",
        "To build a fake news detector, you can use the Real and Fake News dataset available on Kaggle.\n",
        "\n",
        "You can use a pre-trained machine learning model called BERT to perform this classification. BERT is a Natural Language Processing (NLP) model that has been made open-source. You can load BERT into Python and just add one additional output layer for your text classification task.\n",
        "'''"
      ],
      "metadata": {
        "id": "_XjxcL1W4cGo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PegasusForConditionalGeneration, AutoTokenizer"
      ],
      "metadata": {
        "id": "UMuY-pl16KQF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip clone 'https://huggingface.co/google/pegasus-xsum'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqUExCU3I9g1",
        "outputId": "b65ccab3-135a-4217-d2c2-e3078d350d64"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: unknown command \"clone\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('google/pegasus-xsum')"
      ],
      "metadata": {
        "id": "GHltJKGV6cPp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PegasusForConditionalGeneration.from_pretrained('google/pegasus-xsum')"
      ],
      "metadata": {
        "id": "rHsV8dMb66pK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer(text, truncation= True,padding = 'longest',return_tensors = 'pt')"
      ],
      "metadata": {
        "id": "obCjmWVr78JD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAiM9zwt8dO4",
        "outputId": "18501cad-bb9c-4960-e279-f551cad7ca6e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[28965,   990,   117, 15436,   132,  4797,   257,   120,   117, 28813,\n",
              "           130,   990,   107,   168,   117,   432,  1011,   112, 12145,   317,\n",
              "          5695,   111,   440,   990,   108,   111,   126,   875,   123,   144,\n",
              "           430,   109,  1288,  1476, 10520,   165,   113,  9282,   120,   126,\n",
              "           472,   112,   523,   107,   139,  8561,   113,  5695,   990,  2052,\n",
              "           704,  3346,   333,   488,   172,  5614,   132, 41428,  2806,   107,\n",
              "         28965, 28213,   111, 35597,   120,  7310,  4855,   112,   883,   965,\n",
              "           127, 10828,   112,   200,   111,   109,  1996,   107, 28965,   990,\n",
              "           397,   112,   129,  9529,   111, 11890,   616,   108,   269,   126,\n",
              "          2791,  8891,   111, 16607,   112,   114,   423,   344,   113,   200,\n",
              "           107,   413,   736,   114,  5695,   990, 15767,   108,   119,   137,\n",
              "           207,   109,  2817,   111, 28965,  2380, 20886,   293,   124,  1046,\n",
              "         79866,   107,   226,   137,   207,   114,  1133,   121, 14787,  1157,\n",
              "           761,   861,   568,   110, 62613,   112,  1798,   136, 10526,   107,\n",
              "           110, 62613,   117,   114,  4284,  7148, 11430,   143, 72237,   158,\n",
              "           861,   120,   148,   174,   266,   428,   121,  9534,   107,   226,\n",
              "           137,  2638,   110, 62613,   190, 11994,   111,   188,   535,   156,\n",
              "           853,  2940,  2865,   118,   128,  1352, 10526,  1778,   107,   110,\n",
              "             1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = model.generate(**tokens)"
      ],
      "metadata": {
        "id": "Q6yzzAmL9kEt"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(summary[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vvWhhiCjWLhS",
        "outputId": "d08ac638-76cb-4f04-b3ab-1887343d3adb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad> In this tutorial, you will learn how to build a fake news detector.</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}